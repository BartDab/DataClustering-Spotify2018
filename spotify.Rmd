---
title: "DATA CLUSTERING SPOTIFY 2018"
author: "Bartosz Dąbrowski"
date: "5 11 2019"
output: html_document
---

W ramach pierwszego projektu zaliczeniowego na przedmiot Statystyczna Analiza Danych postanowiłem przeprowadzić analizę skupień wybranymi metodami. Data clustering to narzędzie zaliczane do tzw. klasyfikacji bez nauczyciela, co oznacza, że podział na grupy nie jest przez nas nadzorowany, a zależy od algorytmu. To bardzo popularna w uczeniu maszynowym i statystycznym technika, pozwalająca na dobre sklasyfikowanie naszych danych.

Analizowany przeze mnie zbiór to dane dotyczące 100 najpopularniejszych piosenek 2018 roku w serwisie streamingowym Spotify. Spośród dziesiątek milionów utworów, a grupa cieszyła się największą popularnością, a moim celem jest próba zauważenia wyraźnych trendów wśród największych przebojów minionego roku. Do dyspozycji mam 13 parametrów:
- __danceability__ - "taneczność", ustandaryzowana miara tego, jak bardzo piosenka nadaje się do tańca. Na wartość składa się tempo, stabilność rytmu, siła basu i całościowe "uporządkowanie" piosenki.
- __energy__ - energia, ustandaryzowana miara intensywności i dynamiki utworu. Za wartość czynnika odpowiadają głośność, entropia, dynamika, "barwa" utworu i onset rate (?).
- __key__ - wyestymowany klucz piosenki, wysokość dźwięku. 0 = C, 1 = C#, 2 = D... W przypadku, gdy Spotify nie potrafi ustalić klucza, pojawia się wartość -1.
- __loudness__ - uśredniona głośność w decybelach (dB) na przestrzeni całego utworu. Zazwyczaj przyjmuje wartość od -60 do 0, przy czym rozkład ma długi lewy ogon, mediana znajduje się w okolicach -5 - -10.
- __mode__ - modalność piosenki, 0 - minor, 1 - major.
- __speechiness__ - jak bardzo utwór składa się z ludzkiej mowy. Miara ustandaryzowana, 1 oznacza wyłącznie mowę (np. podcasty, audiobooki, poezja), 0 - utwór bez słów. Większość nagrań nie przekracza 0.5.
- __acousticness__ - ustandaryzowana miara prawdopodobnej akustyczności utworu. Im bliżej jedynki, tym z większą pewnością można stwierdzić, że utwór jest akustyczny.
- __instrumentalness__ - ustandaryzowana zmienna, przewidująca, czy utwór jest instrumentalny. Wartości od 0.5 wzwyż najprawdopodobniej oznaczają piosenki bez wokalu, przy czym im bliżej 1, tym większe ejst prawdopododbieństwo słuszności osądu. Onomatopeje i wokal w postaci okrzykóW ("ooo", "aaa", itp.) nie jest traktowany jako śpiew.
- __liveness__ - ustandaryzowana miara, wykrywająca obecność publiczności na nagraniu. Wartości powyżej 0.8 sugerują, że słuchamy wersji "live". W przypadku użytych przeze mnie danych raczej nie spotkamy takich przypadków.
- __valence__ - ustandaryzowany miernik "nastrojowości" - im wyższa wartość, tym weselej brzmi utwory. Najbardziej wyrównany wskaźnik z używanych przez Spotify.
- __tempo__ - liczba uderzeń basu na minutę (beats per minute, BPM), dla ogółu bazy Spotify w przybliżeniu przypomina rozkład normalny.
- __duration_ms__ - długość utworu w milisekundach.
- __time_signature__ - szcowane metrum, liczba uderzeń na takt.
Rozważałem także użycie jako zmiennej artysty, ale wystąpiłoby zbyt duże rozdrobnienie - o ile Drake czy Post Malone mają po 6 utworów w Top 100, o tyle zdecydowana większość artystów ma tylko jedno dzieło w rankingu.

Z takimi danymi zamierzam wyodrębnić kilka grup i zauważyć, czy występują jakieś szczególne zależności w danych. Pytania, które stawiam sobie i danym:
- czy można zauważyć "przepis na hit", a więc czy pewna kombinacja parametrów jest wyraźnie dominująca?
- czy piosenki będące na szczycie listy należą do jednej grupy, czy są podobne?
- czy dużo utworów odbiega od ogólnie przyjętego, "mainstreamowego" schematu (czy dużo jest outlierów)?
Wraz z przeprowadzaniem analizy zapewne pojawią się inne kwestie, na które, mam nadzieję, uda się odpowiedzieć.

Zaczynam od załadowania bibliotek.

```{r}
library(clusterSim)
library(tidyverse)
library(outliers)
library(pacman)
pacman::p_load(pacman,dplyr, ggplot2, plotly,tidyr, rio, gridExtra, scales, ggcorrplot, caret, e1071)
```

Następnie oglądam swoje dane, i, nie przedłużając, badam korelacje pomiędzy zmiennymi.

```{r}
head(top2018)
summary(top2018)
corr<-round(cor(top2018),2)
corr
ggcorrplot(corr)
```

Na tym etapie nie widać nic podejrzanego - najwyższa korelacja występuje pomiędzy key a loudness, i wynosi "zaledwie" 0.73, co choć nie jest wynikiem świetnym, pozwala nam na pozostawienie zmiennych w badaniu. Przechodzę więc do współczynników zmienności.


```{r}
wz<-c()
#top2018[12]
for (i in 1:13)(
  wz[i]=sd(top2018[,i])/mean(top2018[,i])
)
wz
#top2018[4]
```

Widać, że time_signature to zmienna quasi-stała, co znajduje potwierdzenie po przejrzeniu danych w kolumnie - prawie same 4... Bardzo wysoką zmienność mają mode, spechiness, acousticness i instrumentalness, aż zaczynam się zastanawiać, czy nie zbyt wysoką. Tak duże współczynniki prawdopodobnie mogą oznaczać duże rozbicie danych, a więc sporo outlierów. Ale na razie pozbywam się tylko time_signature.

```{r}
head(top2018)
top<-top2018[,-13:-14]
head(top)
for (i in 1:12){
  plot(top[,i])
}
```

Widać kilka kandydatów na outlierów, ale tym zajmę się za chwilę.
Kolejnym etapem jest skalowanie danych, po czym sprawdzę, jak prezentują się na wykresie.

```{r}
top_scale<-scale(top)
round(cor(top_scale,method="kendall"),2)
ggcorrplot(round(cor(top_scale,method="kendall"),2))
head(top_scale,10)
#head(top2018,10)
#top[44,]
#help(plot)
boxplot(top_scale)
summary(top_scale)
#for (i in 1:13){
#  plot(top[,i])
#}
```

Skalowanie wypadło pomyślnie i współczynniki korelacji prezentują się wciąż bardzo dobrze, natomiast wykresy pudełkowe i wartości na moduł potwierdzają to, co wcześniej sugerowały "zwykłe" ploty - w danych jest sporo obserwacji odstających. Występują one w zmiennych danceability, speechiness, acousticness, instrumentalness, liveness oraz duration_ms.

Zrobię coś, co prawdopodobnie powinno zostać wykonane wcześniej.

```{r}
top_df<-as.data.frame(top_scale)
boxplot(top_scale)
top_df<-rownames_to_column(top_df,var='track')
filtr<-filter(top_df, danceability < -3 | speechiness > 3 | acousticness >3 | instrumentalness > 3 | liveness > 3 | duration_ms >3)
top_df<-column_to_rownames(top_df,var="track")
top_df2<-top_df[(top_df$danceability>-3)&(top_df$speechiness<3)&(top_df$acousticness<3)&(top_df$instrumentalness<3)&(top_df$liveness<3)&(top_df$duration_ms<3),]
top_df2
#filter(top_df2, danceability < -3 | speechiness > 3 | acousticness >3 | instrumentalness > 3 | liveness > 3 | duration_ms >3)
boxplot(top_df2)
summary(top_df2)
```

Po oczyszczeniu danych z obserwacji odstających, do dyspozycji mam 89 utworów. Wśród rekordów, które musiałem usunąć, znalazł się utwór "God's Plan" Drake'a. Najczęściej odtwarzana piosenka w 2018, która w chwili tworzenia projektu ma ponad 1,4 mld odsłuchań w serwisie, była outlierem ze względu na zbyt duży współczynnik liveness. Pozostałe outliery prezentują się następująco:

```{r}
filtr
```

Dla pewności, przeprowadzę jeszcze test Grubbsa na obecność obserwacji odstających.

```{r}
top_df_matrix<-as.matrix(top_df2)
grubbs.test(top_df_matrix,type=10)
grubbs.test(top_df_matrix,type=11)
```

P-value przyjmuje wysokie (a w drugim przypadku wręcz bardzo wysokie wartości), co pokazuje, że oczyszczenie regułą 3 sigm spełniło swoje zadanie.

Mogę zająć się teraz funkcją odległości.

```{r}
odl<-dist(top_df2)
#head(odl)
```

```{r}
ward<-hclust(odl,method="ward.D2")
#help(plot)
str(ward)
ward_d<-as.dendrogram(ward)
ward_d

#help(par)
par(mfrow=c(3,1))

plot(ward_d)
plot(cut(ward_d,h=8)$upper, main="Część górna, ucięta na h=8")
plot(cut(ward_d,h=8)$lower[[1]],main="Cz. 1 dolna, h=10")
plot(cut(ward_d,h=8)$lower[[2]],main="Cz. 2 dolna, h=10")
plot(cut(ward_d,h=8)$lower[[3]],main="Cz. 3 dolna, h=10")
plot(cut(ward_d,h=8)$lower[[4]],main="Cz. 4 dolna, h=10")
plot(cut(ward_d,h=8)$lower[[5]],main="Cz. 5 dolna, h=10")
plot(cut(ward_d,h=8)$lower[[6]],main="Cz. 6 dolna, h=10")

#cut<-cutree(ward,k=10);plot(ward,hang=-1);rect.hclust(ward,k=10)
```

Ze względu na ilość danych, podzielenie dendrogramu wydaje się najrozsądniejszą opcją. Po obejrzeniu danych, przechodzę do próby podziału.

```{r}
ward
top_ward<-top_df2
top_ward$grupa<-cutree(ward,k=6)
head(top_ward)
```

```{r}
sylwetka<-c()
for(i in 2:16){
  podzial<-cutree(ward,k=i)
  sylwetka[i]=index.S(odl,podzial)
}
plot(sylwetka,typ="b")
```


```{r}

top2018$grupa<-cutree(ward,k=5)
top2018$grupa
```

```{r}
srednie<-matrix(NA,6,12)
colnames(srednie)<-colnames(top_ward[,1:12])
rownames(srednie)<-c("I","II","III","IV","V","VI")
for (i in 1:6){
  for (j in 1:12){
    srednie[i,]=tapply(top_ward[,j],top_ward$grupa,mean)    
  }
}
srednie
#W TYM MOMENCIE EWIDENTNIE COŚ NIE DZIAŁA
```

```{r}



```